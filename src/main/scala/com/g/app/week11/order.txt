1. Cache vs Persistent
consider if you have rdd which you have generated by doing bunch of transformation
rdd.cache -> results are cached

2.cache and persistent have same purpose -> speed up the application
3.an rdd that is not cached is reevaluated again each time when action is invoked
4.Persistent comes with various storage levels
    i. in memory
    ii. desk
    iii. offheap

    persist() ==  cache() -> inmemory
    cache() -> if no enough storage this will be skipped so use persist instead
    do not cache or persist the base RDD -> whole purpose of cache is to save processing time
    persist(StorageLevel.DISK_ONLY) -> store to disk

    Block Eviction :
        Consider the situation that some block partitions are so large (skew) that they will
        quickly fill up storage memory used for caching

        when the storage memory becomes full, an eviction policy will be used to make up space for new blocks

        LRU (last recently used) -> is used

    Strorage Levels :

    MEMORY_ONLY -> non serialized format i.e srialiazation is  in bytes format
                 -> so takes more memory

    DISK_ONLY ->  serialized format
               -> so less memory
    MEMORY_AND_DISK -> data is cached in memory . If enough memory is not available
                        evicted blocks from memory are serialized to disk
                    -> this mode of operation is recommended when reevaluation is expensive and
                    memory resources are scarce

    OFF_HEAP -> blocks are cached of-heap
               -> save outside of the JVM
               problem with storing objects in jvm is that it used garbage collection for
               freeing up. garbage collection to free up space is a time taking process
               -> but off_heap is unsafe thing as we have to deal with raw memory outside of
               your jvm
    MEMORY_ONLY_SER -> Serialized
    MEMORY_AND_DISK_SER-> Serialized
    MEMORY_ONLY_2-> 2 indicated s replicas stored on 2 different worker Nodes
-----------------------------------------------------------------------------------------------
serialization increases the processing cost but reduces memory footprint
non serialized processing can be fat but more memory footprint

rdd.debugString -> show the lineage


-----------------------------------------------------------------------------------------------
1. Difference between lineage and DAG
2.How to create a jar for your spark project and run in cluster

Lineage : dependency graph
        -> show dependency of various rdd
        -> its a logical plan

DAG is a acyclic graph.
jobs,stages and tasks







