Spark BroadCastVariable
1. val boringWords = sc.broadcast(loadBoringData())
        store the broadcast variable , i.e shared across all the nodes
            a. this is helpful to join
            b.Can be used to reference data
2.flatMapValues(x=>x.split(" "))
        1. if sentence has multiple words "hello how are you ?" , you can use flat map to split them and join them
        for the same key
3. reduceByKey((x,y)=>x+y)
        1. Based on the key you can reduce all the values i.e (good,23), (good,26) => good(49)

4. map(x=>(x.split(",")(10).toFloat,x.split(",")(0)))
    1. You can use split in the map and get the key value pair as well


Accumulator
1. A shared variable that all the nodes  can  update the counter .Its kept in driver machine
2.Executors cannot read the value , but can update the value -> same as counters in the MapReduce

1. Accumulator-> single copy on driver machine
2. broadcast variable -> separate copy in each machine



Narrow Transformation : No Shuffling is required
    1. map
    2.flatmap
    3.Filter


Wide Transformation: Shuffling is required
    1.reduceByKey


 Stage :
    1. marked by shuffle boundaries
        when ever we encounter new shuffle( wide transform) spark creates stage
           total number of stages = basic stage(1) + number of new shuffles
           eg 3 suffles => 1+ 3 = 4 stages

Difference between reduce by key and reduce
1.reducebykey -> transformation (wide)
2.reduce -> action

1.Number of jobs = NUmber of actions
2.When ever you use wide transformation a new stage is created
3.A task corresponds to each partition

groupbykey can lead to out of memory error so never use it


groupByKey vs reduceBykey

1. Both are wide transformation

reduceBykey
1.More working in parallel
2.less shuffling is required
3.Local aggrigation happens

groupByKey
1.Shuffling is required
2.We donot get local aggrigation
3.All the key values are sent (shuffled) to another machine
4.Shuffle more data and less parallelism

never use groupbyKey if you can use reduceByKey




-----------------------------------------------------------------------

1. Pair Rdd - tuple of 2 elements
    ("hello",1)
    ("hi",1)
    ("hello",1)
    Transformations like groupByKey,reduceByKey e.t.c
    Can only work on a pair Rdd

2.Tuple of 2 elements , Is this same as map?
    No it is not map keys are unique where as tuple is not

3.Rdd.savetext("path")-> save the results to file
    this is also action like collect

4.when ever you calla action
    All the transformations from the very beginning are executed

   Action2
   again all the transformations from the very beginning are executed


   So for every action all the transformations are executed
   Having said that spark optimizes internally  and if two jobs have same transformations
   spark will reuse the results

-----------------------------------------------------------------------

1.Sc.defaultParallelism -> gives parallelism implemented on the machine
2.to check number of partitions
    rdd.getNumPartitions -> gives number of partitions in the data
3.Default min partitions -> if less than 2 by default it would have 2
4. Difference between repartition and Coalesce
    repartition -> if you have 200 machines and your code uses 4 partitions increase the partitions i.e
    this happens when you have smaller files
        input.repartition(10) => you will get more parallelization and your code would be fast
        repartition can increase or decrease number of partitions
            decrease  -> 1tb -> 8000blocks -. 1000 node cluster ->  after transformations i.e filter you have
                less since you filter lot of data so in that case its better to reduce the number of partition
    Coalesce-> it can only decrease the number of partitions but cannot increase
           rdd.coalesce(4) -> decrease
           rdd.coalesce(10)-> no change since partitions are decreased

   a. if we want to decrease coalesce is preferred instead of repartition because coalesce
         reduces shuffling,repartition creates huge shuffling because repartition created full shuffling
         Coalesce reduces combines partitions with minimum shuffling
   b.if we want to increase repartition is used





